{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dernameistegal/asp21bpspline/blob/master/PointNet%2B%2B/PointNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r treelearning"
      ],
      "metadata": {
        "id": "QdOQljNz3blJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ7o4vsf3Sn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708483f8-5f42-409c-9f62-0615010f5b59",
        "cellView": "form"
      },
      "source": [
        "#@title Clone repo\n",
        "key = \\\n",
        "\"\"\"\n",
        "-----BEGIN RSA PRIVATE KEY-----\n",
        "MIIJKAIBAAKCAgEAvcWKSRCU6cnVThYINDBAWLj0eAP3Z4jS+kMK/TW1Yb3KcjRM\n",
        "x9BUHB8fTnL6SagNyScU0vzwl+jOROSOP6sUsl67Cq1YKEqdJHhY7/0oB6kZdo2N\n",
        "sip75TT6dUjH31Ht5uSzfV8713MyhhITb9YtmPoPxrGJ9XzTMOYS2n97H08ibxTs\n",
        "vGn6xGK8HELEQqRk9xdsBM2fA0dADLqXmoaYvs3S0ktTl6H92C77eSUv2iH45SRI\n",
        "DDvcEmi4wEvw7ae2SzSYNLiwVOcP98wL2VztvRgdqVCI+9z0GTvaRD78dy1pz/DV\n",
        "fexSYc9Jt/ZhSvyVwBNOCKEiaX4BPfheIkFadWBpJ1OpxbPANPVPTwcdR02hXlPm\n",
        "DuMeX91o2Rc2JJZnWt9OxakYIwOQclDKg1WSTA3fC7eAoKQfEd9oc4lwmSjAVr78\n",
        "si9K4wziKqVPZI4Z3kZ5E4POz/CvRFnzYrWhm4QRTq6kmltKb4mCWHKTmYen5dOF\n",
        "zzJqSJjuTfJtL8qD2U1XUlEFq+7Gcx43TpxnL8ir393UJH6eYsKtz5t6fvE2CcGe\n",
        "GekSTKckw8QHkR/yF01RWlEjGTVtSmy2ZY7ifkp9VUyHzshUntsRAXMZ1bJsglRA\n",
        "z6L/hTOi2wwiPCzKCdbIs7OB98PciE3ZTdVJC+fn7KkNjhkt6JxqQgkANzkCAwEA\n",
        "AQKCAgEAikgGcyVFDXKIHwVI5xZ93OixIz7oqaX27mup90aKq/VLLprTlApHL9Kx\n",
        "0k1P+hoeKYRz1SaA/oCixWqyCMzWIP+MVcRoZ7uu9CNJ015qK+LZbhzJspjofOV0\n",
        "17+3/Q/LRiNCc0nQ5jbICw/i3+x2f3E/y64U9DAICCqudE7OXcshMUZTFxw2oaG8\n",
        "pu8z6ce21qJXkMxwYUgq8NuKmwwXA3ohdCF1gRmGSmA52FXzn4R/xCEC6v83Zqau\n",
        "cVkk71f1KqnhexFVVBim9w7VV4cyqUaIXpcTqkugBz8o1e/7sbAC2YYJW1+3zBPr\n",
        "CMTcsnKJgFPQ2dLoq2wo5Yo0tctfaMRezhpLquIYJlg190IN53aTPvIExBj+N+DW\n",
        "Tg4WfSLoYH/zD7/o3mr8yW2n3RhD6D0GJH1NkwP0mlpA2QprYpR0F5QZQAi1R5KA\n",
        "6kAgWkgJD7duSkLGSurtTENgMv+dXhu7ZB2iPioiGcx548gu9iXLuJMe/C4wiwlt\n",
        "HbiY4qRHLffoCY/u/VCraTJY+6iW0Xu0VUwe2QBrXJsuSX1kWdkpADyfjkPyr6o/\n",
        "AbOqpxMjyqDKEIXd9jyfeUTKN8IyFHvLP3eTshUAKqA6CAA4h1NPkvz1bLLsMRG3\n",
        "E6mziKRen5+I1EIZPOHhipmsXBxtiPzo8l45R2UjmaIFWLBn3Y0CggEBAOxPCiNn\n",
        "geoATBABfklCWkydO9ac4956eFDp0ZDRU2rQ/9uzRPeQ92VmaRvYxO9Ijqmhu80J\n",
        "nYCs/1XVeUkxMXwcJhrSeSNMQ20urWJTDCdJMCm1tZxIbsFaAipA9a/H6HXZBP3Y\n",
        "IOY/G5Th4WIPbG41mMqGqwWogYNZ6frtax1kp8SJNcDqvTXgIIbs2zgo9sOrKom9\n",
        "3i54fuwJ+loWzgKj6yd5eGif9gzuCGVpO+RpXOvrQppytjVOQr9CU9Z8OJPF5QAS\n",
        "vmuluqrKVrCD8gx3mEHJIhhoixoNfJbrti+D49gByKBsI6UtlfnKL/RR4WYxuLLQ\n",
        "rplsrVJfEJawS9MCggEBAM2VxEJn8bTWX8MICF/zdXwVTABO4GYGvCX40HJ0WIaT\n",
        "t0O5RFOrbamQt8Umm13h6UIs9DVEh2UKhgjLBwNq5tNY65mP+TZAVVug33gpHDyI\n",
        "lIHNLxQQYFTUd4FrFW95vpX7bx5tqpCEMic+gfp+9ruHHq/6s3ccfBq6/1e8hQ39\n",
        "lgJq9odoPj1BuSMTSgZ/foHnEA+oLnDCsg+8wFWYQGBC3sj5qP5IqpP7J0bbpQRT\n",
        "M+eA69YyUvVIj1QapP9yFslxYjpPef8FD6llveQdIvxZpqMYykG6TzDU/5dAmYN2\n",
        "JetY8dhyg96e7R85aIyNcg8ReQG3iHzDeT1NLJSRxUMCggEAeAJwEKjphnBeMKbB\n",
        "fu0OtOgJUqXc58jkv5rvjg9wwMehmO8DMINT0RBggv7kjO0ZXra/jJK8hXPWPL4s\n",
        "WWp9Sh11kJuhX7bEa3eQIGYyvuTha91XfSYf8VwHy3OwEnSA7xCnA0+27ZfRJxxL\n",
        "/SP+Gj5n+TrJMhdwpseMF55pjsTmmt5gCThtnSXU/xDdCDltkNOlx8xAQPN66d7r\n",
        "YMNCHn8m1qZO6zuJlulwJCh8fTSxNzMEYTGurYWwSjeiIkR16z5OXWongL3q/f/C\n",
        "ZOStkX1POuGtyh2Vv0ZoJrFQlfLyTGojfK1OsP1ktDXlgrvur5rCxTVL5qkVoMac\n",
        "wxqHdwKCAQAjRYrCieriR9VuNLabH74MZ+r+Moo1dvpY2XOJ74Qwsq9Co0qhwEu0\n",
        "R+v/mzwUw2mtvOC5MuS35TJR1+OAJpsrr5ncYuMy956tddBhYUxC5nv0OSvWmWit\n",
        "pTZLsf+ffJfCS70oz0/wM34XVZYfUCEs02Xkc3LPAMgaHfMpLmL1n4hZKdjaKnxj\n",
        "Lh+BcRHGQ6GE0AvlY8lz9zNtl8i35sNEwLRQbuUbm4QIl5KJia2qLEw/b9MGkOPC\n",
        "yYwttdSRLxXRwe5EatZXdprVSWtm88jI2ujIGry4wipMCn8/iAnOkDq5Qi1cIWmW\n",
        "jFXKgaL6WlozU6AbN03nefIXHmKDqu7ZAoIBAGiIJOk7o4VeEB5xP8PXqrZofHBB\n",
        "47rBlaH2ajtSBSTip31e++3iIBmZvvKu2lLEQXKny+1cJgCbl0ICTducoB6r7ARL\n",
        "U4xbotNgQIyKsMn9rQttqzHVYpbwe1j/eWok5DuRkBuc3Nlcl4B3nPsLD1GKB/QM\n",
        "x/rPv4T8Accr5czgzNZEJfkuI4/9za5gA3ltS90+kJU1IszZxMseuxc7yLEsjAi5\n",
        "2y301P1rqMdQ7xg6JXCjh3yPxQ0ug2ZykFh1X9+DwG86Belqlh56W/nFl298IkTG\n",
        "KIVWo9C9mDm8hm0TGim2KOKNP5rkj7ndETB1S57qi+1amSaGXOcBbLAGzuQ=\n",
        "-----END RSA PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "!mkdir -p /root/.ssh\n",
        "with open(r'/root/.ssh/id_rsa', 'w', encoding=\"utf8\") as fh:\n",
        "    fh.write(key)\n",
        "!ssh-keyscan github.com >> /root/.ssh/known_hosts\n",
        "!chmod 644 /root/.ssh/known_hosts\n",
        "!chmod 600 /root/.ssh/id_rsa\n",
        "!ssh -T git@github.com\n",
        "!git clone git@github.com:jonaden94/treelearning.git\n",
        "!git clone https://github.com/yanx27/Pointnet_Pointnet2_pytorch.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-17a926d7\n",
            "# github.com:22 SSH-2.0-babeld-17a926d7\n",
            "# github.com:22 SSH-2.0-babeld-17a926d7\n",
            "Warning: Permanently added the ECDSA host key for IP address '192.30.255.113' to the list of known hosts.\n",
            "Hi jonaden94/treelearning! You've successfully authenticated, but GitHub does not provide shell access.\n",
            "Cloning into 'treelearning'...\n",
            "remote: Enumerating objects: 660, done.\u001b[K\n",
            "remote: Counting objects: 100% (660/660), done.\u001b[K\n",
            "remote: Compressing objects: 100% (568/568), done.\u001b[K\n",
            "remote: Total 660 (delta 374), reused 264 (delta 79), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (660/660), 39.61 MiB | 11.73 MiB/s, done.\n",
            "Resolving deltas: 100% (374/374), done.\n",
            "Cloning into 'Pointnet_Pointnet2_pytorch'...\n",
            "remote: Enumerating objects: 826, done.\u001b[K\n",
            "remote: Total 826 (delta 0), reused 0 (delta 0), pack-reused 826\u001b[K\n",
            "Receiving objects: 100% (826/826), 68.76 MiB | 8.64 MiB/s, done.\n",
            "Resolving deltas: 100% (478/478), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CxkNtPCI8nl"
      },
      "source": [
        "#@title Imports\n",
        "import os\n",
        "import fastprogress\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBpsMQ_TUwFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2d2505-3884-4cca-bd8c-238a53076f96"
      },
      "source": [
        "#@title Mount drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "import sys \n",
        "sys.path.append(\"/content/treelearning/python\")\n",
        "import data_utils as dt\n",
        "import train_utils as tu \n",
        "from cloud import *\n",
        "import transform as t"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5FPlKWBJMWs",
        "outputId": "6da05ce7-3f0b-4b72-ddac-be500df1348c"
      },
      "source": [
        "device = tu.get_device()\n",
        "num_cpus = os.cpu_count()\n",
        "print(num_cpus, 'CPUs available')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda available: True ; cudnn available: True ; num devices: 1\n",
            "Using device Tesla P100-PCIE-16GB\n",
            "4 CPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pKfxYYTVt1C"
      },
      "source": [
        "forest_path = \"/content/drive/MyDrive/Colab/tree_learning/data/forest_labeled_clean.npy\"\n",
        "position_path = \"/content/drive/MyDrive/Colab/tree_learning/data/positions_relevant.npy\"\n",
        "chunk_path = \"/content/tmp/\"\n",
        "!mkdir tmp"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = t.Compose([t.RandomRotate(), t.ToTensor()])"
      ],
      "metadata": {
        "id": "Wrs_LMO7udYr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW6OQnYqW9Q_"
      },
      "source": [
        "# instantiate TreeDatasetas dataset\n",
        "dataset = dt.TreeDataset(6.9, 50, forest_path, position_path, chunk_path=chunk_path, transform=transform, new_chunks=True, voxel_size=0.03, remove999=True)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "class TreemodDataset(Dataset):\n",
        "    def __init__(self, path=None):\n",
        "        self.items = os.listdir(path)\n",
        "        self.path = path\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        points = np.load(self.path + self.items[key])\n",
        "        points, label = points[:,:3], points[:,3]\n",
        "        points = np.hstack((points, points, points))\n",
        "        coord_max = np.amax(points, axis=0)[:3]\n",
        "        points[:, 6] = points[:, 0] / coord_max[0]\n",
        "        points[:, 7] = points[:, 1] / coord_max[1]\n",
        "        points[:, 8] = points[:, 2] / coord_max[2]\n",
        "        points, label = torch.tensor(points), torch.tensor(label).float()\n",
        "        points = torch.unsqueeze(points, 0)\n",
        "        points = points.transpose(2, 1).float()\n",
        "        return points, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)"
      ],
      "metadata": {
        "id": "6vPPuXSKtRdF"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dat = TreemodDataset(chunk_path)"
      ],
      "metadata": {
        "id": "_teSYx95nmac"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset in 3 parts\n",
        "trainset, valset, testset = dt.split_dataset(dat, split_frac=[0.3, 0.05, 0.65], split_seed=100)"
      ],
      "metadata": {
        "id": "rVm7cTfTrcZ-"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_collate(batch):\n",
        "    \"\"\"\n",
        "    custom collate function since we have a variable number of points per tree and cannot have batches in tensor form\n",
        "    :param batch: batch to calculate return value from\n",
        "    :return: tupel, of points(nx3), targets(nx1), offset(len(batch)) elements\n",
        "    \"\"\"\n",
        "\n",
        "    points, targets = list(zip(*batch))\n",
        "    offset, count = [], 0\n",
        "    for item in points:\n",
        "        count += item.shape[2]\n",
        "        offset.append(count)\n",
        "    return torch.cat(points, dim=2), torch.cat(targets), torch.IntTensor(offset)"
      ],
      "metadata": {
        "id": "urzqeIuI2lRA"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                              batch_size=1,\n",
        "                                              shuffle=False,\n",
        "                                              collate_fn=my_collate,\n",
        "                                              num_workers=num_cpus)\n",
        "\n",
        "    valloader = torch.utils.data.DataLoader(valset,\n",
        "                                            batch_size=1,\n",
        "                                            shuffle=False,\n",
        "                                            collate_fn=my_collate,\n",
        "                                            num_workers=num_cpus)\n"
      ],
      "metadata": {
        "id": "YVkN8Dl11Itk"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUFh98aZuwf4"
      },
      "source": [
        "sys.path.append(\"/content/Pointnet_Pointnet2_pytorch/models\")\n",
        "sys.path.append(\"/content/Pointnet_Pointnet2_pytorch\")\n",
        "import provider\n",
        "import pointnet2_sem_seg as m\n",
        "model = m.get_model(1).to(device)\n",
        "loss_function = m.get_loss().to(device)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import fastprogress\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def get_device(cuda_preference=True):\n",
        "    print('cuda available:', torch.cuda.is_available(),\n",
        "          '; cudnn available:', torch.backends.cudnn.is_available(),\n",
        "          '; num devices:', torch.cuda.device_count())\n",
        "\n",
        "    use_cuda = False if not cuda_preference else torch.cuda.is_available()\n",
        "    device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
        "    device_name = torch.cuda.get_device_name(device) if use_cuda else 'cpu'\n",
        "    print('Using device', device_name)\n",
        "    return device\n",
        "\n",
        "\n",
        "def accuracy(correct, total):\n",
        "    return float(correct) / total\n",
        "\n",
        "\n",
        "def train(dataloader, optimizer, model, loss_fn, device, master_bar):\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "    epoch_correct, epoch_total = 0, 0\n",
        "    sig = nn.Sigmoid()\n",
        "\n",
        "    for x, y, offset in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
        "\n",
        "        # zero gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # initiate loss\n",
        "        loss = 0\n",
        "\n",
        "        # initiate start\n",
        "        start = 0\n",
        "\n",
        "        for border in offset:\n",
        "\n",
        "            points = x[:,:,start:border]\n",
        "            labels = y[start:border]\n",
        "            start = border\n",
        "\n",
        "            # Forward pass\n",
        "            points = points.to(device)\n",
        "            y_pred, _ = model(points)\n",
        "            y_pred = torch.squeeze(y_pred)\n",
        "\n",
        "            # save number of correct classifications and total number of tree points\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Compute loss\n",
        "            y_pred = F.log_softmax(y_pred, dim=1)\n",
        "            loss += 1/len(offset) * loss_fn(y_pred, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        points.detach()\n",
        "        labels.detach()\n",
        "        x.detach()\n",
        "        y.detach()\n",
        "        offset.detach()\n",
        "        # For plotting the train loss, save it for each sample\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "    # Return the mean loss and the accuracy of this epoch\n",
        "    return np.mean(epoch_loss), accuracy(epoch_correct, epoch_total)\n",
        "\n",
        "\n",
        "def validate(dataloader, model, loss_fn, device, master_bar):\n",
        "    model.eval()\n",
        "    epoch_loss = []\n",
        "    epoch_correct, epoch_total = 0, 0\n",
        "    sig = nn.Sigmoid()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y, offset in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
        "\n",
        "            # initiate loss\n",
        "            loss = 0\n",
        "\n",
        "            # initiate start\n",
        "            start = 0\n",
        "\n",
        "            for border in offset:\n",
        "\n",
        "                points = x[:,:,start:border]\n",
        "                labels = y[start:border]\n",
        "                start = border\n",
        "\n",
        "                # make a prediction on validation set\n",
        "                points = points.to(device)\n",
        "                y_pred, _ = model(points)\n",
        "                y_pred = torch.squeeze(y_pred)\n",
        "\n",
        "                # save number of correct classifications and total number of tree points\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Compute loss\n",
        "                y_pred = F.log_softmax(y_pred, dim=1)\n",
        "                loss += 1 / len(offset) * loss_fn(y_pred, labels.int).item()\n",
        "\n",
        "            # For plotting the train loss, save it for each sample\n",
        "            epoch_loss.append(loss)\n",
        "\n",
        "    # Return the mean loss and the accuracy for this epoch\n",
        "    return np.mean(epoch_loss), accuracy(epoch_correct, epoch_total)\n",
        "\n",
        "\n",
        "def run_training(model, optimizer, loss_function, device, num_epochs,\n",
        "                 train_dataloader, val_dataloader, scheduler=None, stopper=None, verbose=False):\n",
        "    start_time = time.time()\n",
        "    master_bar = fastprogress.master_bar(range(num_epochs))\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in master_bar:\n",
        "        # Train the model\n",
        "        epoch_train_loss, epoch_train_acc = train(train_dataloader, optimizer, model,\n",
        "                                                  loss_function, device, master_bar)\n",
        "        # Validate the model\n",
        "        epoch_val_loss, epoch_val_acc = validate(val_dataloader, model, loss_function,\n",
        "                                                 device, master_bar)\n",
        "\n",
        "        # Save loss and acc for plotting\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        val_losses.append(epoch_val_loss)\n",
        "        train_accs.append(epoch_train_acc)\n",
        "        val_accs.append(epoch_val_acc)\n",
        "\n",
        "        if verbose:\n",
        "            master_bar.write(\n",
        "                f'Train loss: {epoch_train_loss:.2f}, val loss: {epoch_val_loss:.2f}, train acc: {epoch_train_acc:.3f}, val acc {epoch_val_acc:.3f}')\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(epoch_val_loss)\n",
        "\n",
        "        if stopper is not None:\n",
        "            stopper.update_patience_spent(val_accs, epoch, model)\n",
        "            if stopper.patience_spent > stopper.patience:\n",
        "                stopper.load_model(model, epoch, start_time)\n",
        "                return train_losses, val_losses, train_accs, val_accs\n",
        "\n",
        "    time_elapsed = np.round(time.time() - start_time, 0).astype(int)\n",
        "    print(f'Finished training after {time_elapsed} seconds.')\n",
        "    return train_losses, val_losses, train_accs, val_accs\n",
        "\n",
        "\n",
        "class EarlyStopper():\n",
        "    \"\"\"Early stops the training if validation accuracy does not increase after a\n",
        "    given patience. Saves and loads model checkpoints.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path='checkpoint.pt', patience=0):\n",
        "        \"\"\"Initialization.\n",
        "        Args:\n",
        "            path (str, optional): Path where checkpoints should be saved.\n",
        "            Defaults to 'checkpoint.pt'\n",
        "            patience (int, optional): Defines how patient the Early stopper is\n",
        "            if accuracy does not increase. Defaults to 0, i.e. stops immediately\n",
        "            if no increase.\n",
        "        \"\"\"\n",
        "        self.path = path\n",
        "        self.current_maximum = 0\n",
        "        self.patience = patience\n",
        "        self.patience_spent = 0\n",
        "\n",
        "    def update_patience_spent(self, val_accs, epoch, model):\n",
        "        if val_accs[epoch] > self.current_maximum:\n",
        "            self.current_maximum = val_accs[epoch]\n",
        "            self.patience_spent = 0\n",
        "            torch.save(model.state_dict(), self.path)\n",
        "        else:\n",
        "            self.patience_spent = self.patience_spent + 1\n",
        "\n",
        "    def load_model(self, model, epoch, start_time):\n",
        "        state_dict = torch.load(self.path)\n",
        "        model.load_state_dict(state_dict)\n",
        "        time_elapsed = np.round(time.time() - start_time, 0).astype(int)\n",
        "        print(f'stopped early after {time_elapsed} seconds and in epoch {epoch + 1}')\n",
        "\n",
        "    def step(self, val_accs, epoch, model):\n",
        "        self.update_patience_spent(val_accs, epoch, model)\n"
      ],
      "metadata": {
        "id": "Yv0hr3lYG5-O"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.memory_summary())\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "oX0OIY8kHhCQ",
        "outputId": "f24c6bdc-e8aa-40d3-8830-e5bc5db2f573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 2            |        cudaMalloc retries: 4         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  611842 KB |   14467 MB |    1171 GB |    1170 GB |\n",
            "|       from large pool |  559877 KB |   14382 MB |     871 GB |     870 GB |\n",
            "|       from small pool |   51965 KB |     126 MB |     299 GB |     299 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  611842 KB |   14467 MB |    1171 GB |    1170 GB |\n",
            "|       from large pool |  559877 KB |   14382 MB |     871 GB |     870 GB |\n",
            "|       from small pool |   51965 KB |     126 MB |     299 GB |     299 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13646 MB |   14962 MB |   29556 MB |   15910 MB |\n",
            "|       from large pool |   13518 MB |   14874 MB |   29428 MB |   15910 MB |\n",
            "|       from small pool |     128 MB |     128 MB |     128 MB |       0 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |  395773 KB |   11960 MB |    1167 GB |    1167 GB |\n",
            "|       from large pool |  369915 KB |   11954 MB |     867 GB |     867 GB |\n",
            "|       from small pool |   25858 KB |      43 MB |     300 GB |     300 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |    1159    |    1857    |   28179 K  |   28178 K  |\n",
            "|       from large pool |      33    |     200    |     102 K  |     102 K  |\n",
            "|       from small pool |    1126    |    1659    |   28076 K  |   28075 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |    1159    |    1857    |   28179 K  |   28178 K  |\n",
            "|       from large pool |      33    |     200    |     102 K  |     102 K  |\n",
            "|       from small pool |    1126    |    1659    |   28076 K  |   28075 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      75    |      75    |      83    |       8    |\n",
            "|       from large pool |      11    |      14    |      19    |       8    |\n",
            "|       from small pool |      64    |      64    |      64    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      76    |     128    |   21920 K  |   21920 K  |\n",
            "|       from large pool |       7    |      21    |      52 K  |      52 K  |\n",
            "|       from small pool |      69    |     112    |   21868 K  |   21868 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jixn1dPGWVu_",
        "outputId": "11a4b3f3-737f-49c5-917a-4abde6863e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "model = m.get_model(2).to(device)\n",
        "def inplace_relu(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('ReLU') != -1:\n",
        "        m.inplace=True\n",
        "model = model.apply(inplace_relu)\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv2d') != -1:\n",
        "        torch.nn.init.xavier_normal_(m.weight.data)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        torch.nn.init.xavier_normal_(m.weight.data)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "model = model.apply(weights_init)\n",
        "loss_function = F.nll_loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "# the higher the pos_weight the more we tend to classify as tree points\n",
        "loss_function = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(1))\n",
        "stopper = tu.EarlyStopper(patience=20)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.2, patience=5, verbose=True)\n",
        "results = run_training(model, optimizer, loss_function, device, num_epochs=100,\n",
        "                 train_dataloader=trainloader, val_dataloader=valloader, \n",
        "                 scheduler=scheduler, stopper=stopper, verbose=True)\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/100 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/77 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-f199c9fc73a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m results = run_training(model, optimizer, loss_function, device, num_epochs=100,\n\u001b[1;32m     25\u001b[0m                  \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                  scheduler=scheduler, stopper=stopper, verbose=True)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-105-5fc087cb8451>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, optimizer, loss_function, device, num_epochs, train_dataloader, val_dataloader, scheduler, stopper, verbose)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         epoch_train_loss, epoch_train_acc = train(train_dataloader, optimizer, model,\n\u001b[0;32m--> 127\u001b[0;31m                                                   loss_function, device, master_bar)\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;31m# Validate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         epoch_val_loss, epoch_val_acc = validate(val_dataloader, model, loss_function,\n",
            "\u001b[0;32m<ipython-input-105-5fc087cb8451>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, optimizer, model, loss_fn, device, master_bar)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    705\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([15304])) must be the same as input size (torch.Size([15304, 2]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%debug"
      ],
      "metadata": {
        "id": "pkYjOo7AF_gz",
        "outputId": "fa10b590-1619-4d33-ae6d-85988acd4824",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m(2532)\u001b[0;36mnll_loss\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m   2530 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   2531 \u001b[0;31m        \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m-> 2532 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   2533 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   2534 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> y_pred\n",
            "*** NameError: name 'y_pred' is not defined\n",
            "ipdb> up\n",
            "> \u001b[0;32m<ipython-input-105-5fc087cb8451>\u001b[0m(59)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     57 \u001b[0;31m            \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     58 \u001b[0;31m            \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 59 \u001b[0;31m            \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     60 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     61 \u001b[0;31m        \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> labels.device\n",
            "device(type='cuda', index=0)\n",
            "ipdb> y_pred.device\n",
            "device(type='cuda', index=0)\n",
            "ipdb> y_pred.shape\n",
            "torch.Size([15304, 2])\n",
            "ipdb> y_pred\n",
            "tensor([[-1.0640, -0.4232],\n",
            "        [-0.6328, -0.7574],\n",
            "        [-0.9212, -0.5076],\n",
            "        ...,\n",
            "        [-1.0590, -0.4259],\n",
            "        [-1.0524, -0.4294],\n",
            "        [-0.8445, -0.5617]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "ipdb> y_pred.dtype\n",
            "torch.float32\n",
            "ipdb> label.dtype\n",
            "*** NameError: name 'label' is not defined\n",
            "ipdb> labels.dtype\n",
            "torch.float32\n",
            "ipdb> quitr\n",
            "*** NameError: name 'quitr' is not defined\n",
            "ipdb> quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1W-cjSaYgWR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "49bcd4b0-43d1-4f7b-f3ce-b8671c637edb"
      },
      "source": [
        "train_losses, val_losses, train_accs, val_accs = results\n",
        "plot(\"Loss\", \"epochs\", train_losses, val_losses, yscale='linear')\n",
        "plot(\"Accuracy\", \"epochs\", train_accs, val_accs, yscale='linear')\n",
        "diag(val_accs, val_losses)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-7cf885eaccdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"checkpoint.pt\")"
      ],
      "metadata": {
        "id": "_3fNL92kwZxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## given model generate predictions on val dataset and save those as a numpy file to be downloaded later\n",
        "# given model generate predictions on val dataset and save those as a numpy file to be downloaded later\n",
        "def gen_pred(path, model, dataset, treenumber, device):\n",
        "    # get desired model\n",
        "    state_dict = torch.load(path)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "\n",
        "    #  generate predictions for single tree\n",
        "    x, y = dataset[treenumber]\n",
        "    pred = model(x.to(device))\n",
        "    sig = nn.Sigmoid()\n",
        "    pred = sig(pred)\n",
        "\n",
        "    # save treepoints, label and predictions in numpy array in this column order\n",
        "    y = y[:, np.newaxis]\n",
        "    x = x.squeeze()\n",
        "    x = x.transpose(0,1)\n",
        "    pred = pred[:, np.newaxis]\n",
        "\n",
        "    pred = pred.cpu().detach().numpy()\n",
        "    x = x.cpu().detach().numpy()\n",
        "    y = y.cpu().detach().numpy()\n",
        "\n",
        "    data = np.hstack([x, y, pred])\n",
        "\n",
        "    return data\n",
        "results = gen_pred(\"checkpoint.pt\", model, dataset, 0, device)\n",
        "np.save(\"results\", results)"
      ],
      "metadata": {
        "id": "LQpFTvtwJ4PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "\n",
        "# We can set the number of bins with the *bins* keyword argument.\n",
        "axs[0].hist(results[:, -1])\n",
        "axs[1].hist(results[:, -2])\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "KDHX3vy_79oN",
        "outputId": "7388c2ce-d94b-46e3-f5b2-a4ed5bc43802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQ/0lEQVR4nO3dfbBcd13H8feXprTDY1sSMp00eouGgSAYyhXrA0xLFdtmNGVgSjoChalGoDg68odBxoHR6ZjqCMpQwSClqUppRTvEaZGH2E5HJEAqpU3aAQKk08TQhAcRZEBav/5xfheWcNO79+7Zu9/c+37N7OzZ33n65uw5+9nz23NPIjORJKmaR026AEmSZmNASZJKMqAkSSUZUJKkkgwoSVJJKyZdAMDKlStzampq0mVIvbvzzju/kpmr+liWx4mWquMdJyUCampqij179ky6DKl3EXF/X8vyONFSdbzjxC4+SVJJBpQkqSQDSpJUkgElSSrJgJIklWRASZJKMqAkSSUZUJKkkgwoSVJJBpQkqaQStzqSJNU0tfWWkeY/sG3jguf1DEqSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSpozoCJibUTcFhH3RsS+iPid1n5GRHwkIj7fnk9v7RERb4uI/RFxd0ScM+5/hCRp6RnmDOoh4PWZuR44F7gyItYDW4FdmbkO2NVeA1wErGuPLcA7eq9akrTkzRlQmXk4M/+jDX8TuA9YA2wCdrTJdgCXtOFNwPXZ2Q2cFhFn9l65JGlJm9dvUBExBTwb+ASwOjMPt1FfBla34TXAAwOzHWxtxy5rS0TsiYg9R48enWfZ0vLgcaLlbOiAiojHAf8I/G5m/vfguMxMIOez4szcnpnTmTm9atWq+cwqLRseJ1rOhgqoiDiZLpz+PjP/qTU/ONN1156PtPZDwNqB2c9qbZIkDW2Yq/gCeDdwX2a+ZWDUTuDyNnw58IGB9le0q/nOBb4x0BUoSdJQVgwxzS8ALwfuiYi7WtsfANuAmyLiCuB+4NI27lbgYmA/8G3gVb1WLElaFuYMqMz8NyCOM/qCWaZP4MoR65IkLXPeSUKSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqac6AiohrI+JIROwdaHtzRByKiLva4+KBcW+IiP0R8dmI+JVxFS5JWtqGOYO6Drhwlva3ZuaG9rgVICLWA5uBZ7R5/ioiTuqrWEnS8jFnQGXmHcDXhlzeJuB9mfndzPwSsB947gj1SZKWqVF+g3pdRNzdugBPb21rgAcGpjnY2iRJmpeFBtQ7gJ8ANgCHgT+f7wIiYktE7ImIPUePHl1gGdLS5nGi5WxBAZWZD2bmw5n5f8C7+EE33iFg7cCkZ7W22ZaxPTOnM3N61apVCylDWvI8TrScLSigIuLMgZcvAmau8NsJbI6IUyLibGAd8MnRSpQkLUcr5pogIm4AzgNWRsRB4E3AeRGxAUjgAPBbAJm5LyJuAu4FHgKuzMyHx1O6JGkpmzOgMvOyWZrf/QjTXwVcNUpRkiR5JwlJUkkGlCSpJANKklSSASVJKsmAkiSVZEBJkkoyoCRJJRlQkqSSDChJUkkGlCSpJANKklSSASVJKsmAkiSVZEBJkkqa87/bkHRimNp6y8jLOLBtYw+VSP3wDEqSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSpozoCLi2og4EhF7B9rOiIiPRMTn2/PprT0i4m0RsT8i7o6Ic8ZZvCRp6RrmDOo64MJj2rYCuzJzHbCrvQa4CFjXHluAd/RTpiRpuZkzoDLzDuBrxzRvAna04R3AJQPt12dnN3BaRJzZV7GSpOVjob9Brc7Mw234y8DqNrwGeGBguoOt7UdExJaI2BMRe44ePbrAMqSlzeNEy9nIF0lkZgK5gPm2Z+Z0Zk6vWrVq1DKkJcnjRMvZQgPqwZmuu/Z8pLUfAtYOTHdWa5MkaV4WGlA7gcvb8OXABwbaX9Gu5jsX+MZAV6AkSUNbMdcEEXEDcB6wMiIOAm8CtgE3RcQVwP3ApW3yW4GLgf3At4FXjaFmSdIyMGdAZeZlxxl1wSzTJnDlqEXNZmrrLSPNf2Dbxp4qkSQtBu8kIUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJW0YpSZI+IA8E3gYeChzJyOiDOAG4Ep4ABwaWZ+fbQyJUnLTR9nUOdn5obMnG6vtwK7MnMdsKu9liRpXsbRxbcJ2NGGdwCXjGEdkqQlbtSASuDDEXFnRGxpbasz83Ab/jKwerYZI2JLROyJiD1Hjx4dsQxpafI40XI2akD9YmaeA1wEXBkRzx8cmZlJF2I/IjO3Z+Z0Zk6vWrVqxDKkpcnjRMvZSAGVmYfa8xHgZuC5wIMRcSZAez4yapGSpOVnwQEVEY+NiMfPDAMvBPYCO4HL22SXAx8YtUhJ0vIzymXmq4GbI2JmOe/NzH+JiE8BN0XEFcD9wKWjlylJWm4WHFCZ+UXgp2dp/ypwwShFSZLknSQkSSUZUJKkkgwoSVJJBpQkqaSRbhZ7IpnaesvIyziwbWMPlUiShuEZlCSpJANKklTSsuni09LTR7ftqOz2lcbHMyhJUkmeQWnevOBE0mIwoE4whoOk5cIuPklSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJL8Q11NRIX76EmqzYBahgwHSScCu/gkSSUZUJKkkgwoSVJJBpQkqSQDSpJUkgElSSrJgJIklWRASZJKMqAkSSV5J4l5GPUODAe2beypEkla+jyDkiSV5BnUIvIeeJI0PM+gJEklGVCSpJIMKElSSQaUJKkkA0qSVJIBJUkqyYCSJJVkQEmSSjKgJEklGVCSpJLGFlARcWFEfDYi9kfE1nGtR5K0NI0loCLiJOAa4CJgPXBZRKwfx7okSUvTuM6gngvsz8wvZub/Au8DNo1pXZKkJWhcdzNfAzww8Pog8LODE0TEFmBLe/mtiPjsmGp5JCuBr0xgvbOpVAtYz1xWAl+Jq+ec7sdHWck8j5ORt9EQ/565VHifKtQANeqYeA1x9VA1zHqcTOy/28jM7cD2Sa0fICL2ZOb0JGuYUakWsJ65LFY98zlOKmwja6hVx4lew7i6+A4Bawden9XaJEkayrgC6lPAuog4OyIeDWwGdo5pXZKkJWgsXXyZ+VBEvA74EHAScG1m7hvHukY00S7GY1SqBaxnLtXqgRo1WcMPVKjjhK4hMrPPQiRJ6oV3kpAklWRASZJKWjIBNdetlSLilRFxNCLuao/faO3nD7TdFRHfiYhL2rjrIuJLA+M2jLueNu5PI2JfRNwXEW+LiGjtz4mIe9oyv98+wXpub8ucmefJi1DL1RGxtz1eOtB+dkR8oi3zxnZxzmJsm+PVs+B9p4d6T2nbYH/bJlN9rXseNfxeRNwbEXdHxK6IGOnvwRZSw8B0L46IjIjeL7cepoaIuLRti30R8d6+aximjoj4sYi4LSI+3d6Ti3te/7URcSQi9h5nfLTPjv1t/ecMteDMPOEfdBdifAF4CvBo4DPA+mOmeSXw9jmWcwbwNeAx7fV1wEsWsx7g54GPtWWcBHwcOK+N+yRwLhDAB4GLJlzP7cD0Im6bjcBH6C7ueSzd1aJPaONuAja34XcCr5lwPQvad3qq97XAO9vwZuDGCdRw/sBx9JpJ1NCmezxwB7B7vvtqT9thHfBp4PT2+skT2ie2zxwTdLefO9BzDc8HzgH2Hmf8xXSfWUH3GfaJYZa7VM6g+rq10kuAD2bmtydYTwKn0u1opwAnAw9GxJl0H367s3vHrwcumVQ9Q87bdy3rgTsy86HM/B/gbuDCdkb3AuD9bbodLM62mbWeIeddqGHq3US3DaDbJhfM52y7jxoy87aB42g33d9C9mnY9+2PgauB7/S8/mFr+E3gmsz8OkBmHplQHQk8oQ0/EfjPPgvIzDvovtwfzybg+uzsBk5rn2mPaKkE1Gy3Vlozy3QvbqeX74+ItbOM3wzccEzbVW2et0bEKeOuJzM/DtwGHG6PD2XmfW3+g0Msc7HqmfGe1oX1h0N+CI7yXn2GLpAeExEr6b6lrwWeBPxXZj40xzIXq54ZC9l3+qj3+9O0bfINum3Ul2G32Ywr6L4992nOGlo30trMvKXndQ9dA/BU4KkR8bGI2B0R4/gCM0wdbwZeFhEHgVuB3x5DHY9kvvsMsHQCahj/DExl5rPoumV2DI5saf5Mur/dmvEG4GnAz9B1//3+uOuJiJ8Enk73jXMN8IKIeF6P6+2znl/PzGcCz2uPl4+zlsz8MN3B9e90XyQ+Djzc0zr7rmec+84JIyJeBkwDf7bI630U8Bbg9Yu53lmsoOvmOw+4DHhXRJw2gTouA67LzLPoutv+tm2j0soXOKQ5b62UmV/NzO+2l38DPOeYZVwK3JyZ3xuY53A7Jf0u8B66U+lx1/MiYHdmfiszv0X3zfPn2vyD3STzuX3UOOohMw+1528C72W47TPSe5WZV2Xmhsz8Zbr+7M8BX6XrMlhxvGUucj2j7Dsj1zs4TdsmT6TbRn0Z6lZmEfFLwBuBXxvYfotVw+OBnwJuj4gDdL977Oz5QolhtsNBYGdmfi8zv0S3f6zrsYZh67iC7nfamV6RU+luJLtYFnb7uz5/KJvUg+5byheBs/nBj4TPOGaaMweGZz50B8fvBs6fbR66D56/ALaNux7gpcBH2zJOBnYBv9rGHXuRxMWTqqe9XtmmOZnut45Xj7mWk4AnteFnAXuBFe31P/DDF0m8dhG2zSPVs6B9p6d6r+SHL5K4aQLH27Ppfrhf1+e651PDMdPfTv8XSQyzHS4EdrThlXTdXE+aQB0fBF7Zhp9O9xtU9FzHFMe/SGIjP3yRxCeHWuY4dp5JPOhOWz/XDoo3trY/ovv2BvAnwL725t0GPO2YDXsIeNQxy/xX4J72wfN3wOPGXU/70Ptr4D7gXuAtA8ucbrV8AXj7fHawvuuhu2rtTroLA/YBfwmcNOZaTm013Ev3hWLDwDKfQhfg++nC6pRF2DaPVM+C950e6j21bYP9bZs8ZQLH20fpLqa5qz12LnYNx0x7Oz0H1JDbIei6Gu9t+8PmvmsYso71dFfjfqa9Hy/sef030P1G/T26s8YrgFfTvrS27XBNq++eYd8Lb3UkSSppqfwGJUlaYgwoSVJJBpQkqSQDSpJUkgElSSrJgJIklWRASZJK+n8T4Qty3V0kxAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = results[:, 4]\n",
        "label = results[:, 3]\n",
        "\n",
        "print(f\"{sum(np.logical_and(label == 1, prediction >= 0.5)) / len(label)*100:.2f} are true positive\")  # true positive\n",
        "print(f\"{sum(np.logical_and(label == 1, prediction <= 0.5)) / len(label)*100:.2f} are false negative\")  # false negative\n",
        "print(f\"{sum(np.logical_and(label == 0, prediction >= 0.5)) / len(label)*100:.2f} are false positive\")  # false positive\n",
        "print(f\"{sum(np.logical_and(label == 0, prediction <= 0.5)) / len(label)*100:.2f} are true negative\")  # true negative"
      ],
      "metadata": {
        "id": "oQDrq7jzGpg_",
        "outputId": "02b73ee7-5277-481c-effe-52bff6dd213f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63.81 are true positive\n",
            "0.00 are false negative\n",
            "36.19 are false positive\n",
            "0.00 are true negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def explore2(datapath, mode=\"pointcloud\", colormode=\"binary\"):\n",
        "\n",
        "    # create pandas dataframe of results\n",
        "    results = np.load(datapath)\n",
        "    prediction = results[:, 4]\n",
        "    label = results[:, 3]\n",
        "    if colormode == \"binary\":\n",
        "        prediction[np.logical_and(label == 1, prediction >= 0.5)] = 1  # true positive\n",
        "        prediction[np.logical_and(label == 1, prediction <= 0.5)] = 2  # false negative\n",
        "        prediction[np.logical_and(label == 0, prediction >= 0.5)] = 3  # false positive\n",
        "        prediction[np.logical_and(label == 0, prediction <= 0.5)] = 4  # true negative\n",
        "        results[:, 4] = prediction\n",
        "    df = pd.DataFrame(data=results, columns=[\"x\", \"y\", \"z\", \"label\", \"prediction\"])\n",
        "\n",
        "    # explore results with pointcloud\n",
        "    if mode == \"pointcloud\":\n",
        "        # create vector of sizes (two sizes for tree and non-tree points)\n",
        "        size = df.iloc[:, -2] * 0.02 + 0.01\n",
        "\n",
        "        fig = px.scatter_3d(df, x='x', y='y', z='z',\n",
        "                            color='prediction',\n",
        "                            symbol='label', size=size, opacity=0, size_max=5)\n",
        "\n",
        "        # tight layout\n",
        "        fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
        "\n",
        "        fig.show()\n",
        "\n",
        "    # explore results with histogram\n",
        "    if mode == \"histogram\":\n",
        "        fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "\n",
        "        # We can set the number of bins with the *bins* keyword argument.\n",
        "        axs[0].hist(results[:, -1])\n",
        "        axs[1].hist(results[:, -2])\n",
        "        fig.show()\n",
        "\n",
        "        return fig"
      ],
      "metadata": {
        "id": "hRMn-gdn46_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(explore2(datapath=\"results.npy\", mode=\"pointcloud\"))"
      ],
      "metadata": {
        "id": "prwS5ZCg_Lw1",
        "outputId": "7f15a2c4-1e75-4d6c-fb6d-709e9c710415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"27d50092-bd7e-48db-b3e4-c8220be9bcc4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"27d50092-bd7e-48db-b3e4-c8220be9bcc4\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '27d50092-bd7e-48db-b3e4-c8220be9bcc4',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"label=1.0<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>size=%{marker.size}<br>prediction=%{marker.color}\", \"legendgroup\": \"label=1.0\", \"marker\": {\"color\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"coloraxis\": \"coloraxis\", \"opacity\": 0, \"size\": [0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746, 0.029999999329447746], \"sizemode\": \"area\", \"sizeref\": 0.0011999999731779098, \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"label=1.0\", \"scene\": \"scene\", \"showlegend\": true, \"type\": \"scatter3d\", \"x\": [-0.13543787598609924, -0.06265738606452942, -1.0795811414718628, -2.015397071838379, 0.18177106976509094, -0.08834604173898697, -0.2971175014972687, 2.2902820110321045, 0.14280474185943604, 0.008341499604284763, 0.6444987654685974, 0.004922911524772644, -0.16301724314689636, -0.11236825585365295, -1.157842993736267, -2.4674618244171143, -0.02473202534019947, 0.07250841706991196, -0.02931668795645237, -0.037655990570783615, 0.44464612007141113, -1.808592677116394, -0.18078768253326416, 0.10672511160373688, -0.622684121131897, 0.2656690180301666, -0.02118363045156002, -0.04113350436091423, -0.04846785217523575, 0.059329889714717865, -0.051262661814689636, 0.038291726261377335, 0.1286710798740387, -0.033975932747125626, -0.1885671764612198, -0.29004746675491333, -0.49732068181037903, 1.0302667617797852, -0.04648236185312271, 0.17495359480381012, 0.25504589080810547, -0.01689545065164566, -0.05884147062897682, -0.06723970174789429, -0.030171122401952744, -0.39476773142814636, 0.049708008766174316, 0.21751700341701508, -0.07539717108011246, -0.07983451336622238, 0.2517364025115967, -0.038637030869722366, 0.5549140572547913, -0.09092535078525543, -0.10631312429904938, -0.04595757648348808, -0.02270006202161312, -1.378167748451233, -0.06667854636907578, -0.06793300807476044, -0.619493842124939, -0.6509364247322083, -0.08750171214342117, -0.0916237160563469, -0.04901755228638649, -0.06046700105071068, -0.06644469499588013, -0.09466803818941116, -0.038933515548706055, -0.10278038680553436, -0.003867941442877054, -0.042513225227594376, -0.8732212781906128, 0.9816321730613708, -0.07787343114614487, -0.07136034965515137, -2.9062421321868896, 2.747053861618042, 0.08110178261995316, -0.05608353018760681, -0.07316586375236511, -0.059384264051914215, -1.17964768409729, 0.012708118185400963, -0.09574942290782928, -0.09951972216367722, -0.1886340081691742, -0.053576454520225525, 1.574514389038086, -1.406693935394287, -0.13944202661514282, -2.4111390113830566, -0.465045690536499, 0.7952165007591248, 0.13450214266777039, 0.17815788090229034, -0.070364810526371, 0.13332831859588623, 1.1478242874145508, -0.48441118001937866, 0.591639518737793, -0.09973437339067459, -0.08602380752563477, -0.1198611781001091, -3.973844051361084, -3.6111373901367188, -3.2916741371154785, -0.618070662021637, -2.7264292240142822, -3.880943536758423, -2.6343276500701904, -1.224408507347107, -0.9548633098602295, -1.0670808553695679, -1.943083643913269, -4.6911845207214355, -3.878094434738159, -1.5939310789108276, -4.01700496673584, -1.0389363765716553, -3.455852746963501, -0.3282172977924347, -1.3492456674575806, -0.3498097062110901, -0.5640135407447815, -0.21786046028137207, -1.4405291080474854, -2.560426712036133, -0.47377458214759827, -0.4457712769508362, -0.5737195611000061, -0.16138145327568054, -0.18686805665493011, -0.1121365949511528, -0.11751306056976318, -1.7642109394073486, -0.14401929080486298, -0.14489948749542236, -0.1706797331571579, -0.11608872562646866, -0.1257188618183136, -0.1398157924413681, -0.15906915068626404, -0.2207449972629547, -0.24768441915512085, 0.5477201342582703, -0.12383370846509933, -0.120591901242733, -0.1281757652759552, -0.11083701252937317, -0.14288082718849182, -0.14690753817558289, -0.09706231206655502, -0.09142942726612091, -0.09093040227890015, -0.1327516734600067, -0.13539916276931763, -0.1419711709022522, -0.16161900758743286, -0.21193428337574005, -0.07432453334331512, -0.10072856396436691, -0.11230967193841934, -0.12876132130622864, 0.4319252073764801, -0.17172610759735107, -0.1272573471069336, -0.10025899857282639, -0.09245508909225464, -1.2397910356521606, -1.1682718992233276, -0.11184701323509216, -0.05980130285024643, -0.07245319336652756, -0.10784976929426193, -0.10501859337091446, -0.08648430556058884, -0.08451076596975327, -0.09992800652980804, -0.09202879667282104, 0.032251909375190735, -0.006459205411374569, -0.07740336656570435, -0.08256669342517853, -0.08083576709032059, -0.08810428529977798, -0.06837445497512817, -0.07095611840486526, -0.10003019869327545, -0.06728111952543259, -0.00025136335170827806, -0.3157743513584137, -0.05085892975330353, -0.03993796557188034, -0.04705226793885231, -0.05649181455373764, -0.02046455629169941, -0.07867854088544846, -0.05064578354358673, -0.01593882031738758, -0.0401354543864727, -0.0842524990439415, 0.003924515563994646, -0.4437088370323181, -0.26182782649993896, -0.037655990570783615, -0.03470005840063095, 0.057612765580415726, -0.016773896291851997, -0.025648588314652443, 0.09644173085689545, -0.014067478477954865, -0.11268024146556854, -0.024915708228945732, -0.009403180330991745, -1.7857578992843628, -1.2667301893234253, -1.3983690738677979, 1.7141259908676147, -1.3686192035675049, -1.1604413986206055, -1.255048155784607, -0.4933161735534668, -0.739541232585907, -0.2929215729236603, -0.8660758137702942, 1.3479152917861938, -0.9600518941879272, -0.680152416229248, -0.5797792673110962, -0.7295349836349487], \"y\": [0.9730475544929504, 0.9730632305145264, -1.2491796016693115, -1.495133638381958, -1.0466562509536743, 1.2050979137420654, -1.3822612762451172, 1.9261873960494995, 1.5073715448379517, 1.4626877307891846, 1.6646231412887573, 1.5141980648040771, 1.627008080482483, 1.866011619567871, -2.1474180221557617, -2.4858946800231934, 0.0005717571475543082, 0.051210638135671616, 0.04361801967024803, 0.03968660160899162, 0.15565931797027588, -0.4305318295955658, -0.07563607394695282, -0.032307133078575134, -0.17531827092170715, 0.15834133327007294, 0.11208592355251312, 0.10963591933250427, 0.09670504927635193, -0.0676015093922615, 0.1227279081940651, 0.13472840189933777, -0.1114170178771019, 0.17788377404212952, -0.2547379434108734, -0.2684035301208496, -0.30388346314430237, 0.4907377064228058, 0.25604763627052307, 0.3059987425804138, 0.35994526743888855, 0.29757609963417053, 0.2881140112876892, 0.3026215732097626, 0.31098344922065735, -0.4222172796726227, 0.3976859450340271, -0.3189535439014435, 0.4114951491355896, 0.4084439277648926, 0.47913858294487, 0.44849100708961487, 0.6438907980918884, 0.4848768711090088, 0.4803805947303772, 0.49912112951278687, 0.5187193155288696, -0.848051130771637, 0.5682560801506042, 0.5874505043029785, -0.6984385251998901, -0.7362850904464722, 0.6014885306358337, 0.6015838384628296, 0.6081194877624512, 0.6270644068717957, 0.6308416128158569, 0.6378016471862793, 0.6770274639129639, 0.664675235748291, 0.7351686954498291, 0.7110742926597595, -0.9278952479362488, 0.9790037274360657, 0.7451279759407043, 0.7435218095779419, -1.4223798513412476, 1.4100483655929565, 0.7902154922485352, 0.8166765570640564, 0.8333257436752319, 0.831308901309967, -1.128234624862671, -0.8879687786102295, 0.874362051486969, 0.9001649022102356, 0.8862134218215942, 0.9146292209625244, 1.2818909883499146, -1.2214815616607666, 0.9362648725509644, -1.4767659902572632, -1.0695487260818481, 3.241438150405884, 3.121098756790161, 3.613781452178955, 3.5884740352630615, 2.0629029273986816, 2.6689977645874023, 2.3428313732147217, 2.694228410720825, 2.6643600463867188, 4.6531243324279785, 4.889471530914307, 3.6602773666381836, 2.0660133361816406, 2.022237777709961, 2.5218067169189453, 1.8432317972183228, 1.403401255607605, 1.703062891960144, 1.983180284500122, 1.8789383172988892, 1.8310716152191162, 1.5699067115783691, 2.7275655269622803, 2.7859153747558594, 3.198659896850586, 2.4019362926483154, 2.76516056060791, 2.21380615234375, 0.8824049234390259, 0.623379647731781, 0.8508808016777039, 0.7779580354690552, 0.765831470489502, 0.47362205386161804, 0.19844481348991394, 0.6096906065940857, 0.6037060022354126, 0.42107462882995605, -0.5479425191879272, 0.4693850576877594, 0.46984079480171204, 0.48913052678108215, 0.07256583869457245, 0.4339452087879181, 0.43784716725349426, 0.3930768668651581, 0.3828386068344116, 0.3755406439304352, 0.3744109272956848, 0.3915954530239105, 0.3787078559398651, 0.3572539985179901, 0.5530819296836853, 0.3626392185688019, 0.3664458990097046, 0.3637100160121918, 0.36864638328552246, 0.3152872920036316, 0.31950458884239197, 0.334849089384079, 0.3371448516845703, 0.31675487756729126, 0.302195280790329, 0.2821206748485565, 0.30216583609580994, -0.3378450870513916, 0.2351273149251938, 0.2794957160949707, 0.26021289825439453, 0.2524748146533966, 0.2754170000553131, -0.17422577738761902, 0.211393341422081, 0.24602757394313812, 0.24904243648052216, 0.25080281496047974, -0.025438295677304268, -0.03800870105624199, 0.20952385663986206, 0.21511346101760864, 0.20303332805633545, 0.21452605724334717, 0.2110641896724701, 0.21524512767791748, 0.17468522489070892, 0.179408460855484, 0.1852908581495285, -0.14751885831356049, -0.18495480716228485, 0.15681108832359314, 0.14334483444690704, 0.14476041495800018, 0.14517106115818024, 0.14859654009342194, 0.14186342060565948, 0.14350596070289612, 0.11193860322237015, 0.1465364694595337, 0.07741162180900574, 0.09821593016386032, 0.10888048261404037, 0.09497412294149399, 0.0959201529622078, 0.09072045981884003, 0.08066403865814209, 0.06545994430780411, 0.0661131888628006, 0.06885597109794617, 0.059929259121418, -0.04011979699134827, -0.04165879264473915, -0.002680656500160694, 0.03968660160899162, 0.03112725168466568, -0.005456104408949614, -0.011984840966761112, -0.01808728650212288, -0.004898153245449066, -0.010349205695092678, -0.00491566164419055, 0.024108244106173515, 0.023507025092840195, 1.5541396141052246, 1.5482056140899658, 1.4682796001434326, -1.3365691900253296, 1.3909300565719604, 1.245166540145874, 1.1510412693023682, 1.327997088432312, 1.1607152223587036, 1.2758146524429321, 1.1126943826675415, -0.953770637512207, 1.0248621702194214, 1.0746747255325317, 1.0614372491836548, 1.0163792371749878], \"z\": [12.779000282287598, 13.793999671936035, 15.920999526977539, 6.382999897003174, 8.854000091552734, 6.039000034332275, 6.139999866485596, 8.845000267028809, 11.416999816894531, 12.880999565124512, 3.2060000896453857, 13.380000114440918, 6.142000198364258, 12.491000175476074, 6.150000095367432, 16.216999053955078, -0.6489999890327454, 1.2309999465942383, -1.0959999561309814, -0.1720000058412552, 5.870999813079834, 15.560999870300293, 9.279999732971191, -0.13300000131130219, 5.982999801635742, 1.2480000257492065, 2.756999969482422, -0.4519999921321869, -0.34299999475479126, -0.6850000023841858, -0.27900001406669617, 4.263999938964844, -1.0390000343322754, 4.443999767303467, 2.4089999198913574, 15.45300006866455, 6.75600004196167, 4.281000137329102, 1.7630000114440918, 7.997000217437744, 8.907999992370605, 6.859000205993652, 2.428999900817871, 3.4140000343322754, 6.172999858856201, 2.4189999103546143, 8.437000274658203, -1.3589999675750732, 8.229999542236328, 8.098999977111816, 12.005999565124512, 8.564000129699707, 3.4230000972747803, 6.743000030517578, 5.9770002365112305, 8.91100025177002, 7.959000110626221, 9.005999565124512, 9.362000465393066, 10.020999908447266, 5.979000091552734, 6.00600004196167, 9.892000198364258, 10.166000366210938, 9.114999771118164, 9.02400016784668, 10.21500015258789, 9.727999687194824, 9.501999855041504, 10.633999824523926, 11.407999992370605, 5.831999778747559, 11.284000396728516, 9.416999816894531, 10.369000434875488, 11.279000282287598, 16.086999893188477, 8.862000465393066, 11.965999603271484, 11.656999588012695, 11.015999794006348, 11.99899959564209, 10.555999755859375, 2.73799991607666, 12.520999908447266, 11.871000289916992, 13.008000373840332, 11.524999618530273, 9.17300033569336, 6.255000114440918, 12.401000022888184, 15.982999801635742, 7.453000068664551, 11.21399974822998, 6.191999912261963, 11.07699966430664, 6.321000099182129, 11.291999816894531, 12.409000396728516, 10.83899974822998, 12.020999908447266, 6.263999938964844, 11.072999954223633, 11.015999794006348, 15.602999687194824, 15.625, 14.274999618530273, 6.388999938964844, 14.26200008392334, 15.133000373840332, 15.567999839782715, 16.93000030517578, 4.980000019073486, 2.871999979019165, 14.338000297546387, 14.232000350952148, 16.406999588012695, 6.25600004196167, 14.199999809265137, 6.334000110626221, 14.229000091552734, 13.118000030517578, 9.763999938964844, 13.194999694824219, 4.386000156402588, 12.432999610900879, 14.831999778747559, 10.286999702453613, 4.386000156402588, 9.22700023651123, 2.617000102996826, -1.4199999570846558, 10.626999855041504, 0.19300000369548798, 14.491000175476074, 15.230999946594238, 6.39900016784668, 5.979000091552734, 5.36299991607666, 7.414999961853027, 7.446000099182129, 5.046000003814697, 5.689000129699707, 7.23199987411499, 7.156000137329102, -1.2940000295639038, 5.830999851226807, 6.622000217437744, 6.533999919891357, 7.65500020980835, 4.7789998054504395, 5.13700008392334, 6.296999931335449, 7.752999782562256, 7.1620001792907715, 5.489999771118164, 4.3460001945495605, 14.831999778747559, -1.4479999542236328, 10.982000350952148, 5.677999973297119, 2.9110000133514404, 3.753000020980835, 4.008999824523926, 12.199999809265137, 4.479000091552734, 4.642000198364258, 3.0929999351501465, 5.2829999923706055, 4.711999893188477, 6.1519999504089355, 2.8570001125335693, 1.0110000371932983, 4.750999927520752, 4.179999828338623, 3.249000072479248, 1.8769999742507935, 1.305999994277954, 1.8580000400543213, 2.4489998817443848, -1.2899999618530273, -1.3580000400543213, 1.0440000295639038, 2.2899999618530273, 3.5759999752044678, 3.803999900817871, 3.322000026702881, 3.884000062942505, 3.0409998893737793, 1.5390000343322754, -0.7699999809265137, 9.144000053405762, 0.04600000008940697, 2.9600000381469727, 2.5480000972747803, 1.1349999904632568, -1.0470000505447388, 0.8059999942779541, 0.3409999907016754, 2.063999891281128, 1.5989999771118164, 0.671999990940094, -1.065999984741211, 3.2170000076293945, 2.1619999408721924, 0.20800000429153442, 0.5640000104904175, 0.597000002861023, -1.2549999952316284, -0.3889999985694885, 0.375, -0.9300000071525574, 8.64900016784668, 0.1080000028014183, 0.7039999961853027, 15.350000381469727, 4.576000213623047, 16.1200008392334, 4.124000072479248, 15.03499984741211, 14.128000259399414, 14.687000274658203, 2.8259999752044678, 7.27400016784668, 9.057000160217285, 13.840999603271484, 4.160999774932861, 14.3100004196167, 13.626999855041504, 12.958000183105469, 13.715999603271484]}, {\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"label=0.0<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>size=%{marker.size}<br>prediction=%{marker.color}\", \"legendgroup\": \"label=0.0\", \"marker\": {\"color\": [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0], \"coloraxis\": \"coloraxis\", \"opacity\": 0, \"size\": [0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582], \"sizemode\": \"area\", \"sizeref\": 0.0011999999731779098, \"symbol\": \"diamond\"}, \"mode\": \"markers\", \"name\": \"label=0.0\", \"scene\": \"scene\", \"showlegend\": true, \"type\": \"scatter3d\", \"x\": [-4.688771724700928, -4.837009906768799, -5.054249286651611, -4.211154937744141, -4.77734899520874, -4.758996486663818, -4.777685165405273, -4.677084922790527, -4.727692604064941, -4.757968902587891, -3.028595209121704, -4.73475456237793, -4.155005931854248, -4.965006351470947, -4.853492259979248, -4.728659152984619, -3.569814920425415, -4.719167709350586, -4.541950702667236, -4.877013206481934, -4.5426177978515625, -4.392576217651367, -4.312504768371582, -4.70282506942749, -4.631789207458496, -4.080887794494629, -4.06736946105957, -3.8524169921875, -4.904000759124756, -3.8805952072143555, -3.8626620769500732, -3.947434425354004, -4.808006286621094, -4.8818278312683105, -3.8496499061584473, -4.350111961364746, -4.8105788230896, -4.9232001304626465, -2.761136054992676, -4.300625324249268, -4.9478440284729, -4.9358296394348145, -4.901562690734863, -5.526795387268066, -4.8134050369262695, -4.845954418182373, -4.4828596115112305, -3.651405096054077, -5.747737407684326, -3.1864173412323, -5.686727046966553, -5.537352561950684, -2.4889793395996094, -5.552313804626465, -4.6131815910339355, -4.7251129150390625, -4.245245456695557, -4.808542728424072, -4.968808650970459, -3.3989975452423096, -2.768618583679199, -5.647506237030029, -4.7940192222595215, -4.794363975524902, -1.756574034690857, -4.7472615242004395, -4.709472179412842, -4.7067952156066895, -5.538102149963379, -1.4964388608932495, -5.430079460144043, -4.814582347869873, -5.502492427825928, -2.723083972930908, -3.7383265495300293, -5.069456100463867, -4.223428249359131, -4.890397548675537, -4.309416770935059, -4.522073268890381, -4.884177207946777, -4.707618713378906, -3.804314136505127, -3.1968963146209717, -2.718871593475342, -5.418624401092529, -4.904584884643555, -5.876780033111572, -5.808017253875732, -4.404332160949707, -4.246888637542725, -2.356032371520996, -4.983624458312988, -3.0025675296783447, -5.5992302894592285, -4.071614742279053, -5.617735385894775, -4.032008171081543, -4.946077346801758, -5.706121921539307, -4.590543746948242, -5.327836513519287, -4.906527519226074, -4.191192626953125, -5.686594486236572, -5.531176567077637, -4.638052940368652, -4.2841620445251465, -4.430419445037842, -5.753944396972656, -1.1041773557662964, -3.9366884231567383, -5.486871719360352, -2.8861215114593506, -4.854592323303223, -5.3490471839904785, -4.920653343200684, -4.88836669921875, -4.554983615875244, -5.720695972442627, -3.178483724594116, -5.760344505310059, -4.933459281921387, -5.972316265106201, -5.662469863891602, -3.7609403133392334, -4.997976303100586, -4.463583469390869, -4.935323238372803, -4.539984703063965, -3.9153342247009277], \"y\": [-2.100238800048828, -2.1111252307891846, -2.2523910999298096, -2.113463878631592, -2.2483608722686768, -2.356984853744507, -2.346848726272583, -2.3292813301086426, -2.3776018619537354, -2.406984329223633, -2.0660815238952637, -2.441727638244629, -2.3396525382995605, -2.5162200927734375, -2.519768476486206, -2.4823827743530273, -2.243525505065918, -2.533548355102539, -2.5284264087677, -2.5927326679229736, -2.5572805404663086, -2.499856472015381, -2.5412514209747314, -2.624173402786255, -2.689134359359741, -2.5546116828918457, -2.609994649887085, -2.5676567554473877, -2.8366501331329346, -2.6426966190338135, -2.6540281772613525, -2.669050455093384, -2.87137770652771, -2.8849549293518066, -2.720801591873169, -2.856247663497925, -2.9826719760894775, -3.00602650642395, -2.5019099712371826, -2.8983912467956543, -3.0331132411956787, -3.0591065883636475, -3.056502342224121, -1.3482120037078857, -1.2159901857376099, -1.2807399034500122, -1.2316375970840454, -1.0820093154907227, -1.5866751670837402, -1.1483144760131836, -1.7389830350875854, -1.7104129791259766, -1.0135403871536255, -1.780421257019043, -1.621880054473877, -1.6573807001113892, -1.5942386388778687, -1.7192559242248535, -1.7677099704742432, -1.4238461256027222, -1.3144505023956299, -1.9628394842147827, -1.7836381196975708, -1.7775652408599854, -1.1292105913162231, -1.7864173650741577, -1.9357624053955078, -1.9249073266983032, -2.120633125305176, -1.241726040840149, -2.117793083190918, -2.0015032291412354, -2.164881706237793, -3.615840435028076, -4.327692031860352, -3.162033796310425, -2.990665912628174, -3.2241549491882324, -3.100274085998535, -3.148244857788086, -3.2699074745178223, -3.398200750350952, -3.3307766914367676, -3.469515800476074, 2.1596505641937256, 1.2215795516967773, 1.2832038402557373, 1.0167421102523804, 0.9164140224456787, 1.1787230968475342, 1.1260780096054077, 3.2051186561584473, 2.0198678970336914, 0.27707958221435547, -0.3363493084907532, 0.008247402496635914, -0.34974974393844604, -0.03099910356104374, -0.2597460150718689, -0.4896276593208313, -0.25437963008880615, -0.4760536551475525, -0.4168950021266937, -0.3160135746002197, -0.6943486332893372, -0.6562143564224243, -0.5254790186882019, -0.5491867065429688, -0.5688525438308716, -0.9002150297164917, 0.10049000382423401, -0.567166268825531, -0.9435070753097534, -0.4890759587287903, -0.9197933077812195, -1.0682361125946045, -0.9859516620635986, -0.9745680093765259, -0.9618967771530151, 0.6429254412651062, 1.188714623451233, 0.4914889931678772, 0.6113830208778381, 0.26325035095214844, 0.2757379412651062, 0.6441989541053772, 0.26571333408355713, 0.30527567863464355, 0.14247947931289673, 0.14862385392189026, 0.2516017258167267], \"z\": [22.099000930786133, 22.516000747680664, 19.579999923706055, 20.944000244140625, 21.702999114990234, 20.086000442504883, 21.552000045776367, 20.719999313354492, 20.312999725341797, 21.249000549316406, 20.621000289916992, 21.716999053955078, 27.405000686645508, 20.034000396728516, 18.878000259399414, 20.45400047302246, 20.365999221801758, 19.961000442504883, 21.316999435424805, 18.715999603271484, 20.937000274658203, 21.56399917602539, 22.069000244140625, 18.243999481201172, 19.2549991607666, 22.597999572753906, 22.941999435424805, 19.84000015258789, 18.106000900268555, 24.742000579833984, 24.125999450683594, 26.236000061035156, 18.43199920654297, 17.905000686645508, 25.408000946044922, 27.670000076293945, 18.110000610351562, 17.650999069213867, 24.19700050354004, 18.926000595092773, 17.260000228881836, 17.079999923706055, 16.861000061035156, 18.73900032043457, 21.089000701904297, 25.29199981689453, 20.972000122070312, 22.952999114990234, 21.010000228881836, 21.32699966430664, 20.829999923706055, 18.607999801635742, 23.089000701904297, 18.569000244140625, 20.65999984741211, 24.020000457763672, 22.641000747680664, 24.451000213623047, 20.049999237060547, 21.95199966430664, 20.865999221801758, 20.60300064086914, 23.625, 23.93000030517578, 23.874000549316406, 20.75200080871582, 20.469999313354492, 20.427000045776367, 18.448999404907227, 21.99799919128418, 18.433000564575195, 23.038999557495117, 18.402000427246094, 22.259000778198242, 21.884000778198242, 16.849000930786133, 19.05299949645996, 16.304000854492188, 18.68899917602539, 17.83799934387207, 17.302000045776367, 16.733999252319336, 20.266000747680664, 20.940000534057617, 22.10700035095215, 21.43000030517578, 20.961999893188477, 19.38800048828125, 19.322999954223633, 21.85700035095215, 22.375999450683594, 22.131999969482422, 20.9060001373291, 25.610000610351562, 19.131999969482422, 21.72800064086914, 19.121999740600586, 21.60700035095215, 21.357999801635742, 21.95400047302246, 27.527999877929688, 27.356000900268555, 21.322999954223633, 21.493000030517578, 21.746999740600586, 18.948999404907227, 25.44300079345703, 21.35700035095215, 26.00200080871582, 21.57200050354004, 23.489999771118164, 24.573999404907227, 18.882999420166016, 23.0310001373291, 26.121999740600586, 26.961000442504883, 26.224000930786133, 21.215999603271484, 27.283000946044922, 22.875999450683594, 21.944000244140625, 19.2549991607666, 21.135000228881836, 22.677000045776367, 19.194000244140625, 21.764999389648438, 22.42099952697754, 25.527000427246094, 21.29199981689453, 23.53700065612793, 21.631999969482422]}],\n",
              "                        {\"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"prediction\"}}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"legend\": {\"itemsizing\": \"constant\", \"tracegroupgap\": 0}, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"scene\": {\"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"xaxis\": {\"title\": {\"text\": \"x\"}}, \"yaxis\": {\"title\": {\"text\": \"y\"}}, \"zaxis\": {\"title\": {\"text\": \"z\"}}}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('27d50092-bd7e-48db-b3e4-c8220be9bcc4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oPTCP92iGPOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}